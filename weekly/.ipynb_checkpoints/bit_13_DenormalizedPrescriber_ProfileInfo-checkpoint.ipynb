{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenormalizedPrescriber ProfileInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "data_date = js['data_date']\n",
    "num_weeks_rx = js['num_weeks_rx']\n",
    "num_weeks_calls = js['num_weeks_calls']\n",
    "IBSC_ptype_file = js['IBSC_ptype_file']\n",
    "bucket = js['bucket']\n",
    "\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'\n",
    "xpn = f's3://{bucket}/PYADM/weekly/archive/{data_date}/xponent/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions -\n",
    "def load(df, lib=dflib):\n",
    "    globals()[df] = pl.read_parquet(f'{lib}{df}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imporing Dependencies\n",
    "load('mp_spec_seg_dec')\n",
    "load('MASTER_UNI')\n",
    "prod_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/productmapping_pybit.txt',separator='|')\n",
    "ibsc_ptype = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/{IBSC_ptype_file}.xlsx'))\n",
    "geo_code_mapper = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/geo_id_full.xlsx'))\n",
    "\n",
    "load('temp_calls')\n",
    "fetch_products = ['LI1','LI2','LI3','TRU','AMT','LAC','MOT','LUB','IRL']\n",
    "\n",
    "#fixes for vortex import -> Probably caused by Polars Upgrades\n",
    "temp_calls = temp_calls.with_columns(pl.col('SalesRepIID').cast(pl.Int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_summed_period_iid_metric(metric,prod_cd):\n",
    "    columns = ['IID','PROD_CD'] + [metric+str(i) for i in range(1,106)]\n",
    "    df = pl.read_parquet(xpn+'LAX.parquet',columns=columns).filter(pl.col('PROD_CD').is_in(prod_cd))\n",
    "\n",
    "    # 1,4,13,26 for current and prior period for a given Metric\n",
    "    df = df.select(\n",
    "        pl.col('IID'),pl.col('PROD_CD'),\n",
    "        pl.col(metric+'1').alias(metric+'_1c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,5)]).alias(metric+'_4c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,14)]).alias(metric+'_13c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,27)]).alias(metric+'_26c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,num_weeks_rx+1)]).alias(metric+'_qtdc'),\n",
    "\n",
    "        pl.col(metric+'2').alias(metric+'_1p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(5,9)]).alias(metric+'_4p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(14,27)]).alias(metric+'_13p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(27,53)]).alias(metric+'_26p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(14,14+num_weeks_rx)]).alias(metric+'_qtdp'),\n",
    "\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,106)]).alias(metric+'_all')\n",
    "    )\n",
    "\n",
    "    # Adding MP related columns\n",
    "    df = df.join(mp_spec_seg_dec,on='IID',how='left').filter(pl.col('geography_id').is_not_null())\n",
    "\n",
    "    return(df.drop(['specialty_group','segment','decile','geography_id']))\n",
    "\n",
    "all_products_tuf = get_summed_period_iid_metric('TUF',fetch_products)\n",
    "all_products_nuf = get_summed_period_iid_metric('NUF',fetch_products)\n",
    "\n",
    "def add_parent_product_rows(df):\n",
    "    agg_dict = {}\n",
    "    for col in df.columns[2:]:\n",
    "        agg_dict[col] = pl.col(col).sum()\n",
    "    \n",
    "    #join_cols = ['geography_id','plan_type','PlanID','IID']\n",
    "\n",
    "    df = df.join(prod_mapping[['code','product_id','parent_product_id']], left_on = 'PROD_CD',right_on = 'code', how = 'left')\n",
    "    df_2_35 = df.filter(pl.col('parent_product_id').is_in([2,35]))\n",
    "    df_2_35 = df_2_35.group_by(['IID','parent_product_id']).agg(**agg_dict).rename({'parent_product_id':'product_id'})\n",
    "    \n",
    "    df_1 = df.group_by('IID').agg(**agg_dict).with_columns(product_id = pl.lit(1)).with_columns(pl.col('product_id').cast(pl.Int64))\n",
    "\n",
    "    # stack 1, 2_35 with df and return\n",
    "    df = df.drop(['PROD_CD','parent_product_id']) #dropping to make same shape\n",
    "    vstack_helper = df.columns\n",
    "    df = df.vstack(\n",
    "        df_2_35.select(vstack_helper)\n",
    "    ).vstack(\n",
    "        df_1.select(vstack_helper)\n",
    "    )\n",
    "\n",
    "    return(df)\n",
    "\n",
    "all_products_tuf = add_parent_product_rows(all_products_tuf)\n",
    "all_products_nuf = add_parent_product_rows(all_products_nuf)\n",
    "\n",
    "tuf1 = all_products_tuf.filter(pl.col('TUF_all')!=0).select(['IID','product_id'])\n",
    "nuf1 = all_products_nuf.filter(pl.col('NUF_all')!=0).select(['IID','product_id'])\n",
    "xponent = tuf1.join(nuf1,on=['IID','product_id'],how='outer_coalesce')\n",
    "\n",
    "calls = (\n",
    "    temp_calls.filter(pl.col('call_week')<= num_weeks_calls)\n",
    "    .rename({'AttendeeIID':'IID'})\n",
    "    .select('IID').unique('IID')\n",
    "    .with_columns(product_id = pl.lit(2)).with_columns(pl.col('product_id').cast(pl.Int64))\n",
    ")\n",
    "\n",
    "xponent_calls = xponent.join(calls,on=['IID','product_id'],how='outer_coalesce')\n",
    "\n",
    "#delete extra dfs when optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Processing - \n",
    "temp1 = MASTER_UNI.select(\n",
    "    [\n",
    "        'IID','FirstName','LastName','CREDENTIAL','PDRPOptOutFlag',\n",
    "        'AddressLine1','AddressLine2','AddressLine3','AddressLine4','CityName','StateCode','ZIP','DECILE'\n",
    "    ]\n",
    ").with_columns(\n",
    "    pl.concat_str([pl.col('AddressLine1'),pl.col('AddressLine2'),pl.col('AddressLine3'),pl.col('AddressLine4')],separator=' ').alias('Address'),\n",
    "    pl.concat_str([pl.col('FirstName'),pl.col('LastName')],separator=' ').alias('Physician_Name'),\n",
    "    pl.when(pl.col('PDRPOptOutFlag')=='Y').then(1).otherwise(0).alias('PDRPOptOutFlag'),\n",
    "    pl.lit(1).alias('Product_id')\n",
    ").join(\n",
    "    mp_spec_seg_dec.drop('decile'),on='IID',how='left'\n",
    ").join(\n",
    "    ibsc_ptype,on='IID',how='left'\n",
    ").drop(['AddressLine1','AddressLine2','AddressLine3','AddressLine4','FirstName','LastName']\n",
    ").with_columns(\n",
    "    pl.lit(None).alias('Urgent_Care_HCP'),\n",
    "    pl.lit('WEEKLY').alias('ReportType')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# filter step-\n",
    "temp1 = temp1.filter(\n",
    "    pl.col('IID').is_in(xponent_calls['IID'].unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Creating Feed Ready Data -\n",
    "rename_dict = {\n",
    "    'IID':'Physician_ID',\n",
    "    'geography_id':'Geography_id',\n",
    "    'CityName':'City',\n",
    "    'StateCode':'State',\n",
    "    'ZIP':'Zip',\n",
    "    'PDRPOptOutFlag':'IsPDRP',\n",
    "    'segment':'Segment',\n",
    "    'IBSC_VALUE':'IBSCPrimaryPayerType',\n",
    "    'specialty_group':'Specialty',\n",
    "    'CREDENTIAL':'Credential',\n",
    "    'DECILE':'Decile'\n",
    "}\n",
    "temp1 = temp1.rename(rename_dict)\n",
    "select_list = [\n",
    "    'Physician_Name','Physician_ID','Geography_id','Product_id','ReportType','Urgent_Care_HCP','Address','City',\n",
    "    'State','Zip','IsPDRP','Segment','IBSCPrimaryPayerType','Specialty','Credential','Decile'\n",
    "]\n",
    "temp1 = temp1.select(select_list)# last dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T14:09:57.110752Z",
     "iopub.status.busy": "2024-05-23T14:09:57.110182Z",
     "iopub.status.idle": "2024-05-23T14:10:06.659703Z",
     "shell.execute_reply": "2024-05-23T14:10:06.658692Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denorm Presc Profile Info Exported !\n"
     ]
    }
   ],
   "source": [
    "#Exporting Feeds-\n",
    "OUT = 's3://vortex-staging-a65ced90/BIT/output/DenormalizedPrescriber/Weekly/'\n",
    "temp1.to_pandas().to_csv(f'{OUT}Weekly_DenormalizedPrescriber_ProfileInfo_Feed.txt', sep='|')\n",
    "print('Denorm Presc Profile Info Exported !')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
